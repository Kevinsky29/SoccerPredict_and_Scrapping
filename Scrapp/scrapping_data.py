# -*- coding: utf-8 -*-
"""Scrapping_Data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16VlPIL5Bu7bD6Kr7MpFarDz0MwIXsDP1

#Soccer Data Scrapping

Create all funtions to scrap data for teams
"""

import requests
from bs4 import BeautifulSoup
import json
import pandas as pd

import ipywidgets as widgets
from IPython.display import display

class TeamScraper: #class for the scrapping
    def __init__(self, team, year_season):
        self.team = team
        self.year_season = year_season
        self.url = self._build_url()

    def _build_url(self):#First build url for a team
        base_url = 'https://understat.com/team/'
        return base_url + self.team + '/' + str(self.year_season)

    def scrape_team_data(self):#Now scrap the matches and results
        res = requests.get(self.url)
        soup = BeautifulSoup(res.content, 'lxml')
        scripts = soup.find_all('script')

        strings_season = scripts[1].string

        ind_start = strings_season.index("('") + 2
        ind_end = strings_season.index("')")

        json_data = strings_season[ind_start:ind_end]
        json_data = json_data.encode('utf8').decode('unicode_escape')

        data = json.loads(json_data)

        df = pd.json_normalize(data)

        df = pd.DataFrame(data)

        keys = ['h', 'a', 'goals', 'xG', 'forecast']

        for key in keys:
            df_normalized = pd.json_normalize(df[key])
            df = pd.concat([df, df_normalized], axis=1)

        df = df.drop(columns=['forecast', 'a', 'h', 'xG', 'goals'])

        df = df.rename(columns={'h': 'home', 'a': 'away'})
        df = df.rename(columns={'w': 'win', 'd': 'draw', 'l': 'loss'})
        df = df.replace({'h': 'home', 'a': 'away'})



        df['season'] = f"{str(self.year_season)}/{str(self.year_season + 1)}"


        df['point'] = df['result'].map({'w': 3, 'd': 1, 'l': 0})
        df['points'] = df['point'].cumsum()

        filename = f"{self.team}_{self.year_season}.csv"
        df.to_csv(filename, index=False)
        print("Data saved to", filename)

        return df

    def scrape_team_players(self):#Now scrap the data of the players
        res = requests.get(self.url)
        soup = BeautifulSoup(res.content, 'lxml')
        scripts = soup.find_all('script')

        strings_players = scripts[3].string

        ind_start = strings_players.index("('") + 2
        ind_end = strings_players.index("')")

        json_data = strings_players[ind_start:ind_end]
        json_data = json_data.encode('utf8').decode('unicode_escape')

        data_players = json.loads(json_data)

        df_players = pd.DataFrame(data_players)

        df_players['season'] = f"{str(self.year_season)}/{str(self.year_season + 1)}"

        team = df_players['team_title'].unique()

        filename_players = team[0] + "_" + str(self.year_season) + "_players.csv"
        df_players.to_csv(filename_players, index=False)
        print("Player data saved to", filename_players)

        return df_players, team

    def read_match_data(self, filename):#Scrap all the info for the matches
        df = pd.read_csv(filename)
        matches = df['id'].unique()

        base_url_match = 'https://understat.com/match/'
        matches = df['id'].tolist()

        self.data_list = []
        self.counter = 1
        self.data_names = []

        for match in matches:
            url_match = base_url_match + str(match)

            res = requests.get(url_match)
            soup = BeautifulSoup(res.content, 'lxml')
            scripts_match = soup.find_all('script')

            strings_match_list = []

            for script in scripts_match:
                if script.string:
                    strings_match_list.append(script.string)

                strings_match = scripts_match[1].string

            ind_start = strings_match.index("('") + 2
            ind_end = strings_match.index("')")

            json_data = strings_match[ind_start:ind_end]
            json_data = json_data.encode('utf8').decode('unicode_escape')

            data_match = json.loads(json_data)
            self.data_list.append(data_match)


            new_list_name = f"data_list_{self.counter}"
            self.data_names.append(new_list_name)
            globals()[new_list_name] = data_match

            self.counter += 1

        df_matches = self.convert_to_dataframe(self.data_names)
        return df_matches, self.data_names

    def convert_to_dataframe(self, data_names):#Convert dataframes
        combined_data = []

        for data_name in data_names:
            data = globals()[data_name]
            data_home = data['h']
            data_away = data['a']

            combined_data.extend(data_home)
            combined_data.extend(data_away)

        df_matches = pd.DataFrame(combined_data)

        # Agregar la columna "season" al dataframe
        df_matches['season'] = f"{str(self.year_season)}/{str(self.year_season + 1)}"
        return df_matches

    def read_match_data_all(self, df_matches, team):
        df_matches = df_matches
        self.data_names = df_matches.columns.tolist()

        man_city_players = df_matches.loc[(df_matches['h_team'] == team[0]) | (df_matches['a_team'] == team[0]), 'player'].unique()
        man_city_situation = df_matches.loc[(df_matches['h_team'] == team[0]) | (df_matches['a_team'] == team[0]), 'result'].unique()

        self.dropdown_jugadores = widgets.Dropdown(
            options=man_city_players,
            description='Selecciona un jugador:'
        )
        self.dropdown_situation = widgets.Dropdown(
            options=man_city_situation,
            description='Selecciona una situaci√≥n:'
        )

"""#Call the funtions and save all in a dataframe"""

year_seasons = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]
team = input('Enter the team name:')

season_dfs = []
player_dfs = []
matches_dfs = []

for year_season in year_seasons:
    team_scraper = TeamScraper(team, year_season)

    team_data = team_scraper.scrape_team_data()
    season_dfs.append(team_data)

    team_players, team_name = team_scraper.scrape_team_players()
    player_dfs.append(team_players)

    filename = f"{team}_{year_season}.csv"
    match_data, data_names = team_scraper.read_match_data(filename)

    df_matches = team_scraper.convert_to_dataframe(data_names)
    df_matches['season'] = f"{str(year_season)}/{str(year_season + 1)}"

    matches_dfs.append(df_matches)

all_matches_df = pd.concat(matches_dfs)
all_matches_df.to_csv('MC_matches.csv', index=False)
df_compiled = pd.concat(season_dfs)
df_compiled.to_csv('MC_seasons.csv', index=False)
df_compiled_players = pd.concat(player_dfs)
df_compiled_players.to_csv('MC_players.csv', index=False)